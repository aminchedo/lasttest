import express from 'express';
import { createWriteStream, existsSync, mkdirSync } from 'fs';
import path from 'path';
import { randomUUID } from 'crypto';
import fetch from 'node-fetch';
import { pipeline } from 'stream/promises';

const router = express.Router();

// ØªÙˆÚ©Ù† Hugging Face - Ø¬Ø§ÛŒÚ¯Ø²ÛŒÙ† Ú©Ù†ÛŒØ¯ Ø¨Ø§ ØªÙˆÚ©Ù† ÙˆØ§Ù‚Ø¹ÛŒ
const HF_TOKEN = process.env.HF_TOKEN || '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';
const JOBS = new Map();

// ØªØ§Ø¨Ø¹ Ø¨Ø±Ø§ÛŒ Ø¯Ø±ÛŒØ§ÙØª Ù„ÛŒØ³Øª ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ÛŒ Ù…Ø¯Ù„
async function getModelFiles(modelId) {
  try {
    const headers = HF_TOKEN ? { Authorization: `Bearer ${HF_TOKEN}` } : {};
    const response = await fetch(
      `https://huggingface.co/api/models/${modelId}`,
      { headers }
    );
    
    if (!response.ok) {
      throw new Error(`Failed to fetch model info: ${response.status}`);
    }
    
    const modelInfo = await response.json();
    return modelInfo;
  } catch (error) {
    console.error('Error fetching model files:', error);
    throw error;
  }
}

// ØªØ§Ø¨Ø¹ Ø¨Ø±Ø§ÛŒ Ø¯Ø§Ù†Ù„ÙˆØ¯ ÙØ§ÛŒÙ„
async function downloadFile(modelId, filename, destPath, job) {
  const headers = HF_TOKEN ? { Authorization: `Bearer ${HF_TOKEN}` } : {};
  const url = `https://huggingface.co/${modelId}/resolve/main/${filename}`;
  
  try {
    console.log(`ðŸ“¥ Downloading: ${url}`);
    
    const response = await fetch(url, { headers });
    if (!response.ok) {
      throw new Error(`HTTP ${response.status} for ${url}`);
    }
    
    const contentLength = response.headers.get('content-length');
    const totalSize = contentLength ? parseInt(contentLength, 10) : 0;
    
    // Ø§ÛŒØ¬Ø§Ø¯ Ø¯Ø§ÛŒØ±Ú©ØªÙˆØ±ÛŒ Ù…Ù‚ØµØ¯
    const dir = path.dirname(destPath);
    if (!existsSync(dir)) {
      mkdirSync(dir, { recursive: true });
    }
    
    const writer = createWriteStream(destPath);
    let downloadedSize = 0;
    
    // Ù…Ø¯ÛŒØ±ÛŒØª Ø¬Ø±ÛŒØ§Ù† Ø¯Ø§Ù†Ù„ÙˆØ¯
    if (!response.body) {
      throw new Error('No response body');
    }
    
    for await (const chunk of response.body) {
      downloadedSize += chunk.length;
      writer.write(chunk);
      
      // Ø¨Ø±ÙˆØ²Ø±Ø³Ø§Ù†ÛŒ Ù¾ÛŒØ´Ø±ÙØª
      if (totalSize > 0) {
        const fileProgress = (downloadedSize / totalSize) * 100;
        job.files[filename] = {
          progress: Math.round(fileProgress),
          downloaded: downloadedSize,
          total: totalSize
        };
        
        // Ù…Ø­Ø§Ø³Ø¨Ù‡ Ù¾ÛŒØ´Ø±ÙØª Ú©Ù„ÛŒ
        updateOverallProgress(job);
      }
    }
    
    writer.end();
    console.log(`âœ… Downloaded: ${filename}`);
    return true;
    
  } catch (error) {
    console.error(`âŒ Error downloading ${filename}:`, error);
    throw error;
  }
}

// ØªØ§Ø¨Ø¹ Ø¨Ø±ÙˆØ²Ø±Ø³Ø§Ù†ÛŒ Ù¾ÛŒØ´Ø±ÙØª Ú©Ù„ÛŒ
function updateOverallProgress(job) {
  const files = Object.values(job.files);
  if (files.length === 0) return;
  
  const totalProgress = files.reduce((sum, file) => sum + file.progress, 0) / files.length;
  job.progress = Math.round(totalProgress);
}

// ØªØ§Ø¨Ø¹ Ø§ØµÙ„ÛŒ Ø¯Ø§Ù†Ù„ÙˆØ¯ Ù…Ø¯Ù„
async function downloadModel(modelId, targetDir, jobId) {
  const job = JOBS.get(jobId);
  if (!job) return;
  
  try {
    job.status = 'fetching_model_info';
    job.progress = 5;
    
    // Ø¯Ø±ÛŒØ§ÙØª Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ù…Ø¯Ù„
    const modelInfo = await getModelFiles(modelId);
    job.status = 'downloading_files';
    job.progress = 10;
    
    // ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ÛŒ Ø¶Ø±ÙˆØ±ÛŒ Ø¨Ø±Ø§ÛŒ Ø¯Ø§Ù†Ù„ÙˆØ¯
    const essentialFiles = [
      'config.json',
      'pytorch_model.bin',
      'model.safetensors',
      'tokenizer.json',
      'vocab.json',
      'tokenizer_config.json',
      'special_tokens_map.json'
    ];
    
    // ÙÛŒÙ„ØªØ± ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ÛŒ Ù…ÙˆØ¬ÙˆØ¯
    const filesToDownload = essentialFiles.filter(file => {
      // Ø¯Ø± Ø§ÛŒÙ†Ø¬Ø§ Ù…ÛŒâ€ŒØªÙˆØ§Ù†ÛŒØ¯ Ø¨Ø±Ø±Ø³ÛŒ Ú©Ù†ÛŒØ¯ Ú©Ù‡ ÙØ§ÛŒÙ„ ÙˆØ§Ù‚Ø¹Ø§Ù‹ ÙˆØ¬ÙˆØ¯ Ø¯Ø§Ø±Ø¯
      return true; // Ø¨Ø±Ø§ÛŒ Ø³Ø§Ø¯Ú¯ÛŒ Ù‡Ù…Ù‡ ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ Ø±Ø§ Ø¯Ø§Ù†Ù„ÙˆØ¯ Ù…ÛŒâ€ŒÚ©Ù†ÛŒÙ…
    });
    
    job.totalFiles = filesToDownload.length;
    job.downloadedFiles = 0;
    job.files = {};
    
    // Ø¯Ø§Ù†Ù„ÙˆØ¯ Ù‡Ø± ÙØ§ÛŒÙ„
    for (const filename of filesToDownload) {
      if (job.status === 'cancelled') break;
      
      const destPath = path.join(targetDir, modelId.replace('/', '_'), filename);
      job.currentFile = filename;
      
      try {
        await downloadFile(modelId, filename, destPath, job);
        job.downloadedFiles++;
        
        // Ø¨Ø±ÙˆØ²Ø±Ø³Ø§Ù†ÛŒ Ù¾ÛŒØ´Ø±ÙØª Ø¨Ø± Ø§Ø³Ø§Ø³ ØªØ¹Ø¯Ø§Ø¯ ÙØ§ÛŒÙ„â€ŒÙ‡Ø§
        const fileProgress = (job.downloadedFiles / job.totalFiles) * 80; // 80% Ø¨Ø±Ø§ÛŒ ÙØ§ÛŒÙ„â€ŒÙ‡Ø§
        job.progress = 10 + Math.round(fileProgress);
        
      } catch (error) {
        console.error(`Failed to download ${filename}:`, error);
        job.errors = job.errors || [];
        job.errors.push(`Failed to download ${filename}: ${error.message}`);
      }
    }
    
    if (job.errors && job.errors.length > 0) {
      job.status = 'error';
      job.error = `Failed to download ${job.errors.length} files`;
    } else {
      job.status = 'completed';
      job.progress = 100;
      job.completedAt = new Date().toISOString();
    }
    
  } catch (error) {
    console.error('Download failed:', error);
    job.status = 'error';
    job.error = error.message;
    job.progress = 0;
  }
}

// Route Ø´Ø±ÙˆØ¹ Ø¯Ø§Ù†Ù„ÙˆØ¯
router.post('/api/hf/download', async (req, res) => {
  try {
    const { modelId, targetDir = './models' } = req.body;
    
    if (!modelId) {
      return res.status(400).json({ 
        ok: false, 
        error: 'Model ID is required' 
      });
    }
    
    const jobId = randomUUID();
    const job = {
      id: jobId,
      modelId,
      targetDir,
      status: 'queued',
      progress: 0,
      files: {},
      createdAt: new Date().toISOString(),
      startedAt: null,
      completedAt: null,
      error: null
    };
    
    JOBS.set(jobId, job);
    
    // Ø´Ø±ÙˆØ¹ Ø¯Ø§Ù†Ù„ÙˆØ¯ Ø¯Ø± Ù¾Ø³â€ŒØ²Ù…ÛŒÙ†Ù‡
    setTimeout(() => {
      job.status = 'downloading';
      job.startedAt = new Date().toISOString();
      downloadModel(modelId, targetDir, jobId);
    }, 1000);
    
    res.json({ 
      ok: true, 
      jobId,
      message: `Download started for model: ${modelId}`
    });
    
  } catch (error) {
    console.error('Error starting download:', error);
    res.status(500).json({ 
      ok: false, 
      error: 'Failed to start download' 
    });
  }
});

// Route Ø¨Ø±Ø±Ø³ÛŒ ÙˆØ¶Ø¹ÛŒØª
router.get('/api/hf/status/:jobId', (req, res) => {
  const job = JOBS.get(req.params.jobId);
  
  if (!job) {
    return res.status(404).json({ 
      ok: false, 
      error: 'Job not found' 
    });
  }
  
  res.json({
    ok: true,
    data: {
      jobId: job.id,
      status: job.status,
      progress: job.progress,
      modelId: job.modelId,
      currentFile: job.currentFile,
      downloadedFiles: job.downloadedFiles,
      totalFiles: job.totalFiles,
      files: job.files,
      error: job.error,
      createdAt: job.createdAt,
      startedAt: job.startedAt,
      completedAt: job.completedAt
    }
  });
});

// Route Ù„ÛŒØ³Øª Ø¬Ø§Ø¨â€ŒÙ‡Ø§
router.get('/api/hf/jobs', (req, res) => {
  const jobs = Array.from(JOBS.values());
  res.json({ 
    ok: true, 
    data: jobs 
  });
});

// Route Ù„ØºÙˆ Ø¯Ø§Ù†Ù„ÙˆØ¯
router.post('/api/hf/cancel/:jobId', (req, res) => {
  const job = JOBS.get(req.params.jobId);
  
  if (!job) {
    return res.status(404).json({ 
      ok: false, 
      error: 'Job not found' 
    });
  }
  
  if (job.status === 'downloading') {
    job.status = 'cancelled';
    job.progress = 0;
    job.error = 'Download cancelled by user';
  }
  
  res.json({ 
    ok: true, 
    message: 'Download cancelled' 
  });
});

export default router;