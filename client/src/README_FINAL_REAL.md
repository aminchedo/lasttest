# ğŸš€ Ø³ÛŒØ³ØªÙ… Ø¢Ù…ÙˆØ²Ø´ Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ AI - Ø±Ø§Ù‡Ù†Ù…Ø§ÛŒ Ù†Ù‡Ø§ÛŒÛŒ

## ğŸ“¦ ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ÛŒ Ù¾Ø±ÙˆÚ˜Ù‡

### ğŸ”· **TypeScript API**
1. **[types.ts](computer:///mnt/user-data/outputs/types.ts)** - Type definitions Ú©Ø§Ù…Ù„
2. **[client.ts](computer:///mnt/user-data/outputs/client.ts)** - API Client Ø¨Ø§ WebSocket
3. **[Dashboard.tsx](computer:///mnt/user-data/outputs/Dashboard.tsx)** - Dashboard Ø¨Ø§ TypeScript

### ğŸ¤– **Ù…Ø¯Ù„â€ŒÙ‡Ø§ Ùˆ Ø¢Ù…ÙˆØ²Ø´**
4. **[MODELS_GUIDE.md](computer:///mnt/user-data/outputs/MODELS_GUIDE.md)** - Ø±Ø§Ù‡Ù†Ù…Ø§ÛŒ Ú©Ø§Ù…Ù„ Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Hugging Face
5. **[download_models.py](computer:///mnt/user-data/outputs/download_models.py)** - Ø§Ø³Ú©Ø±ÛŒÙ¾Øª Ø¯Ø§Ù†Ù„ÙˆØ¯ Ø®ÙˆØ¯Ú©Ø§Ø±

### ğŸ“š **Ù…Ø³ØªÙ†Ø¯Ø§Øª**
6. **[.env.example](computer:///mnt/user-data/outputs/.env.example)** - Environment variables
7. **[DEPLOYMENT_GUIDE.md](computer:///mnt/user-data/outputs/DEPLOYMENT_GUIDE.md)** - Ø±Ø§Ù‡Ù†Ù…Ø§ÛŒ VPS

---

## ğŸ¯ Ø´Ø±ÙˆØ¹ Ø³Ø±ÛŒØ¹

### Ù…Ø±Ø­Ù„Ù‡ 1: Ù†ØµØ¨ Dependencies

```bash
# Backend
cd backend
pip install -r requirements.txt

# Frontend
cd frontend
npm install
```

### Ù…Ø±Ø­Ù„Ù‡ 2: Ø¯Ø§Ù†Ù„ÙˆØ¯ Ù…Ø¯Ù„â€ŒÙ‡Ø§ Ø§Ø² Hugging Face

```bash
# Ø¯Ø§Ù†Ù„ÙˆØ¯ Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Ù¾Ø§ÛŒÙ‡ (ParsBERT + GPT2-Persian)
python download_models.py

# ÛŒØ§ Ø¯Ø§Ù†Ù„ÙˆØ¯ Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Ø®Ø§Øµ
python download_models.py --models parsbert,gpt2-persian,mt5-base

# Ù„ÛŒØ³Øª Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Ù…ÙˆØ¬ÙˆØ¯
python download_models.py --list
```

**Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯ÛŒ**:
- **ParsBERT**: https://huggingface.co/HooshvareLab/bert-fa-base-uncased (440MB)
- **GPT2-Persian**: https://huggingface.co/flax-community/gpt2-persian (500MB)
- **mT5-Base**: https://huggingface.co/google/mt5-base (2.3GB)
- **XLM-RoBERTa**: https://huggingface.co/xlm-roberta-base (1.1GB)

### Ù…Ø±Ø­Ù„Ù‡ 3: ØªÙ†Ø¸ÛŒÙ… Environment

```bash
# Ú©Ù¾ÛŒ .env.example
cp .env.example .env

# ÙˆÛŒØ±Ø§ÛŒØ´ .env
nano .env
```

```env
# Backend API
VITE_API_URL=http://localhost:8000/api
VITE_WS_URL=ws://localhost:8000/ws
```

### Ù…Ø±Ø­Ù„Ù‡ 4: Ø§Ø¬Ø±Ø§ÛŒ Backend

```bash
cd backend
uvicorn main:app --reload --host 0.0.0.0 --port 8000
```

### Ù…Ø±Ø­Ù„Ù‡ 5: Ø§Ø¬Ø±Ø§ÛŒ Frontend

```bash
cd frontend
npm run dev
```

Ø¨Ø±Ùˆ Ø¨Ù‡: http://localhost:5173

---

## ğŸ—ï¸ Ø³Ø§Ø®ØªØ§Ø± Ù¾Ø±ÙˆÚ˜Ù‡

```
project/
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ models/                  # Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Ø¯Ø§Ù†Ù„ÙˆØ¯ Ø´Ø¯Ù‡
â”‚   â”‚   â”œâ”€â”€ parsbert/
â”‚   â”‚   â”œâ”€â”€ gpt2-persian/
â”‚   â”‚   â””â”€â”€ mt5-base/
â”‚   â”œâ”€â”€ datasets/               # Ø¯ÛŒØªØ§Ø³Øªâ€ŒÙ‡Ø§ÛŒ Ø¢Ù…ÙˆØ²Ø´ÛŒ
â”‚   â”œâ”€â”€ checkpoints/            # Checkpoints
â”‚   â”œâ”€â”€ api/
â”‚   â”‚   â”œâ”€â”€ training.py        # Training endpoints
â”‚   â”‚   â”œâ”€â”€ models.py          # Models endpoints
â”‚   â”‚   â””â”€â”€ datasets.py        # Datasets endpoints
â”‚   â”œâ”€â”€ requirements.txt
â”‚   â””â”€â”€ main.py
â”‚
â””â”€â”€ frontend/
    â”œâ”€â”€ src/
    â”‚   â”œâ”€â”€ api/
    â”‚   â”‚   â”œâ”€â”€ types.ts       # Type definitions
    â”‚   â”‚   â””â”€â”€ client.ts      # API Client
    â”‚   â”œâ”€â”€ pages/
    â”‚   â”‚   â””â”€â”€ Dashboard.tsx  # Dashboard
    â”‚   â””â”€â”€ main.tsx
    â”œâ”€â”€ .env
    â””â”€â”€ package.json
```

---

## ğŸ”Œ API Endpoints

### Dashboard
```typescript
// Ø¢Ù…Ø§Ø± Ú©Ù„ÛŒ
const stats = await apiClient.getDashboardStats();

// ÙˆØ¶Ø¹ÛŒØª Ø³ÛŒØ³ØªÙ…
const status = await apiClient.getSystemStatus();

// Ù…ØªØ±ÛŒÚ©â€ŒÙ‡Ø§ÛŒ real-time
const metrics = await apiClient.getSystemMetrics();
```

### Models
```typescript
// Ù„ÛŒØ³Øª Ù…Ø¯Ù„â€ŒÙ‡Ø§
const models = await apiClient.getModels();

// Ø¬Ø²Ø¦ÛŒØ§Øª ÛŒÚ© Ù…Ø¯Ù„
const model = await apiClient.getModel('parsbert');
```

### Training
```typescript
// Ø´Ø±ÙˆØ¹ Ø¢Ù…ÙˆØ²Ø´
const job = await apiClient.startTraining({
  baseModel: 'parsbert',
  datasets: ['dataset-1'],
  modelName: 'my-model',
  config: {
    epochs: 10,
    batchSize: 32,
    learningRate: 2e-5,
    optimizer: 'adamw'
  }
});

// Ù…Ø¯ÛŒØ±ÛŒØª training
await apiClient.pauseTraining(job.id);
await apiClient.resumeTraining(job.id);
await apiClient.stopTraining(job.id);
```

### WebSocket - Real-time Updates
```typescript
// Subscribe Ø¨Ù‡ Ù…ØªØ±ÛŒÚ©â€ŒÙ‡Ø§
const unsubscribe = apiClient.subscribeToMetrics((metrics) => {
  console.log('CPU:', metrics.cpu);
  console.log('GPU:', metrics.gpu);
});

// Subscribe Ø¨Ù‡ training progress
apiClient.subscribeToTraining(jobId, (update) => {
  console.log('Progress:', update.progress);
  console.log('Loss:', update.metrics.valLoss);
});
```

---

## ğŸ¤– Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Hugging Face

### Ø¯Ø§Ù†Ù„ÙˆØ¯ Ù…Ø¯Ù„ Ø¨Ø§ Python

```python
from transformers import AutoModel, AutoTokenizer

# Ø¯Ø§Ù†Ù„ÙˆØ¯ ParsBERT
model = AutoModel.from_pretrained("HooshvareLab/bert-fa-base-uncased")
tokenizer = AutoTokenizer.from_pretrained("HooshvareLab/bert-fa-base-uncased")

# Ø°Ø®ÛŒØ±Ù‡ local
model.save_pretrained("./models/parsbert")
tokenizer.save_pretrained("./models/parsbert")
```

### Fine-tuning Ù…Ø¯Ù„

```python
from transformers import Trainer, TrainingArguments

training_args = TrainingArguments(
    output_dir="./results",
    num_train_epochs=3,
    per_device_train_batch_size=32,
    learning_rate=2e-5,
    fp16=True,  # Mixed Precision
)

trainer = Trainer(
    model=model,
    args=training_args,
    train_dataset=train_dataset,
    eval_dataset=eval_dataset,
)

trainer.train()
```

Ø¨Ø±Ø§ÛŒ Ø¬Ø²Ø¦ÛŒØ§Øª Ø¨ÛŒØ´ØªØ±: **[MODELS_GUIDE.md](computer:///mnt/user-data/outputs/MODELS_GUIDE.md)**

---

## ğŸ“Š Ø¯ÛŒØªØ§Ø³Øªâ€ŒÙ‡Ø§ÛŒ ÙØ§Ø±Ø³ÛŒ

### Ø¯Ø§Ù†Ù„ÙˆØ¯ Ø§Ø² Hugging Face

```python
from datasets import load_dataset

# Persian News
dataset = load_dataset("persiannlp/parsinlu_reading_comprehension")

# Sentiment Analysis
dataset = load_dataset("HooshvareLab/sentiment-fa")

# Question Answering
dataset = load_dataset("persiannlp/parsinlu_multiple_choice")
```

### ÙØ±Ù…Øª Ø¯ÛŒØªØ§Ø³Øª Ø¨Ø±Ø§ÛŒ Ø¢Ù…ÙˆØ²Ø´

```json
{
  "train": [
    {
      "text": "Ø§ÛŒÙ† ÛŒÚ© Ù…ØªÙ† ÙØ§Ø±Ø³ÛŒ Ø§Ø³Øª",
      "label": 0
    }
  ],
  "validation": [
    {
      "text": "Ù…ØªÙ† Ø¯ÛŒÚ¯Ø±ÛŒ Ø¨Ø±Ø§ÛŒ validation",
      "label": 1
    }
  ]
}
```

---

## ğŸ”¥ ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§ÛŒ Ú©Ù„ÛŒØ¯ÛŒ

### âœ… Type Safety Ø¨Ø§ TypeScript
```typescript
// Ù‡Ù…Ù‡ Ú†ÛŒØ² Type-safe
const stats: DashboardStats = await apiClient.getDashboardStats();
// IntelliSense Ú©Ø§Ù…Ù„
// Compile-time error checking
```

### âœ… Real-time Ø¨Ø§ WebSocket
```typescript
// Auto-reconnect
// Heartbeat
// Event subscriptions
```

### âœ… Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ ÙˆØ§Ù‚Ø¹ÛŒ Hugging Face
- ParsBERT Ø¨Ø±Ø§ÛŒ Classification
- GPT2-Persian Ø¨Ø±Ø§ÛŒ Text Generation
- mT5 Ø¨Ø±Ø§ÛŒ Translation
- XLM-RoBERTa Ø¨Ø±Ø§ÛŒ Multilingual

### âœ… Training Ù¾ÛŒØ´Ø±ÙØªÙ‡
- Mixed Precision (FP16)
- Gradient Accumulation
- Auto-recovery from failures
- Checkpoint management
- Auto-tuning hyperparameters

---

## âš¡ Ø¨Ù‡ÛŒÙ†Ù‡â€ŒØ³Ø§Ø²ÛŒ

### 1. Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Mixed Precision
```python
training_args = TrainingArguments(
    fp16=True,  # Ú©Ø§Ù‡Ø´ 50% Ù…ØµØ±Ù Ø­Ø§ÙØ¸Ù‡
    ...
)
```

### 2. Gradient Accumulation
```python
training_args = TrainingArguments(
    gradient_accumulation_steps=4,
    per_device_train_batch_size=8,  # effective batch = 32
    ...
)
```

### 3. Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² LoRA (PEFT)
```python
from peft import get_peft_model, LoraConfig

peft_config = LoraConfig(
    task_type=TaskType.SEQ_CLS,
    r=16,
    lora_alpha=16,
)

model = get_peft_model(model, peft_config)
# ÙÙ‚Ø· 1% Ù¾Ø§Ø±Ø§Ù…ØªØ±Ù‡Ø§ Ø¢Ù…ÙˆØ²Ø´ Ù…ÛŒâ€ŒØ¨ÛŒÙ†Ù†!
```

---

## ğŸ“ˆ Ù…Ø«Ø§Ù„ Ú©Ø§Ù…Ù„ End-to-End

### 1. Ø¯Ø§Ù†Ù„ÙˆØ¯ Ù…Ø¯Ù„
```bash
python download_models.py --models parsbert
```

### 2. Ø¢Ù…Ø§Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ Ø¯ÛŒØªØ§Ø³Øª
```python
from datasets import Dataset

data = {
    "text": ["Ù…ØªÙ† Ø§ÙˆÙ„", "Ù…ØªÙ† Ø¯ÙˆÙ…"],
    "label": [0, 1]
}
dataset = Dataset.from_dict(data)
dataset.save_to_disk("./datasets/my-dataset")
```

### 3. Ø´Ø±ÙˆØ¹ Ø¢Ù…ÙˆØ²Ø´ Ø§Ø² Frontend
```typescript
const job = await apiClient.startTraining({
  baseModel: 'parsbert',
  datasets: ['my-dataset'],
  modelName: 'my-fine-tuned-model',
  config: {
    epochs: 10,
    batchSize: 32,
    learningRate: 2e-5,
    optimizer: 'adamw',
    mixedPrecision: true
  }
});
```

### 4. Ù…Ø§Ù†ÛŒØªÙˆØ±ÛŒÙ†Ú¯ Real-time
```typescript
apiClient.subscribeToTraining(job.id, (update) => {
  console.log(`Epoch ${update.currentEpoch}/${job.totalEpochs}`);
  console.log(`Loss: ${update.metrics.valLoss}`);
  console.log(`Accuracy: ${update.metrics.valAccuracy}%`);
});
```

### 5. Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ù…Ø¯Ù„ Ø¢Ù…ÙˆØ²Ø´ Ø¯Ø§Ø¯Ù‡ Ø´Ø¯Ù‡
```python
from transformers import pipeline

classifier = pipeline("sentiment-analysis", model="./checkpoints/job-1/final")
result = classifier("Ø§ÛŒÙ† Ù…Ø­ØµÙˆÙ„ Ø¹Ø§Ù„ÛŒ Ø§Ø³Øª!")
```

---

## ğŸ¯ Requirements

### Backend
```txt
fastapi==0.104.1
uvicorn==0.24.0
transformers==4.35.0
torch==2.1.0
datasets==2.14.6
accelerate==0.24.1
peft==0.6.2
websockets==12.0
```

### Frontend
```json
{
  "dependencies": {
    "react": "^18.2.0",
    "typescript": "^5.0.0",
    "recharts": "^2.10.0",
    "framer-motion": "^10.16.0",
    "lucide-react": "^0.300.0"
  }
}
```

---

## ğŸš€ Deployment

### Development
```bash
# Backend
cd backend && uvicorn main:app --reload

# Frontend
cd frontend && npm run dev
```

### Production
```bash
# Build Frontend
npm run build

# Deploy Ø¨Ø§ Docker
docker-compose up -d
```

Ø¨Ø±Ø§ÛŒ Ø¬Ø²Ø¦ÛŒØ§Øª Ø¨ÛŒØ´ØªØ±: **[DEPLOYMENT_GUIDE.md](computer:///mnt/user-data/outputs/DEPLOYMENT_GUIDE.md)**

---

## ğŸ“š Ù…Ø³ØªÙ†Ø¯Ø§Øª

1. **[MODELS_GUIDE.md](computer:///mnt/user-data/outputs/MODELS_GUIDE.md)** - Ø±Ø§Ù‡Ù†Ù…Ø§ÛŒ Ú©Ø§Ù…Ù„ Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Hugging Face
2. **[DEPLOYMENT_GUIDE.md](computer:///mnt/user-data/outputs/DEPLOYMENT_GUIDE.md)** - Ø±Ø§Ù‡Ù†Ù…Ø§ÛŒ deployment Ø±ÙˆÛŒ VPS

---

## ğŸ”§ Troubleshooting

### Ù…Ø´Ú©Ù„: Model not found
```bash
# Ø¯Ø§Ù†Ù„ÙˆØ¯ Ù…Ø¬Ø¯Ø¯ Ù…Ø¯Ù„
python download_models.py --models parsbert
```

### Ù…Ø´Ú©Ù„: CUDA out of memory
```python
# Ú©Ø§Ù‡Ø´ batch size
training_args = TrainingArguments(
    per_device_train_batch_size=8,  # Ú©Ø§Ù‡Ø´ Ø§Ø² 32 Ø¨Ù‡ 8
    gradient_accumulation_steps=4,   # Ø¬Ø¨Ø±Ø§Ù† Ø¨Ø§ accumulation
)
```

### Ù…Ø´Ú©Ù„: WebSocket connection failed
```bash
# Ú†Ú© Ú©Ø±Ø¯Ù† Backend
curl http://localhost:8000/health

# Ú†Ú© Ú©Ø±Ø¯Ù† .env
VITE_WS_URL=ws://localhost:8000/ws
```

---

## ğŸ“ Ù¾Ø´ØªÛŒØ¨Ø§Ù†ÛŒ

- **Hugging Face Hub**: https://huggingface.co/models
- **Transformers Docs**: https://huggingface.co/docs/transformers
- **FastAPI Docs**: https://fastapi.tiangolo.com

---

## âœ… Checklist Ù†Ù‡Ø§ÛŒÛŒ

### Ù‚Ø¨Ù„ Ø§Ø² Ø´Ø±ÙˆØ¹:
- [ ] Dependencies Ù†ØµØ¨ Ø´Ø¯ (pip + npm)
- [ ] Ù…Ø¯Ù„â€ŒÙ‡Ø§ Ø§Ø² Hugging Face Ø¯Ø§Ù†Ù„ÙˆØ¯ Ø´Ø¯
- [ ] .env ÙØ§ÛŒÙ„ ØªÙ†Ø¸ÛŒÙ… Ø´Ø¯
- [ ] Backend Ø±ÙˆÛŒ port 8000 Ø¯Ø± Ø­Ø§Ù„ Ø§Ø¬Ø±Ø§Ø³Øª
- [ ] Frontend Ø±ÙˆÛŒ port 5173 Ø¯Ø± Ø­Ø§Ù„ Ø§Ø¬Ø±Ø§Ø³Øª

### Ø¨Ø±Ø§ÛŒ Production:
- [ ] Ù…Ø¯Ù„â€ŒÙ‡Ø§ Ø±ÙˆÛŒ VPS Ø¯Ø§Ù†Ù„ÙˆØ¯ Ø´Ø¯Ù†
- [ ] Environment variables ØªÙ†Ø¸ÛŒÙ… Ø´Ø¯Ù†
- [ ] HTTPS ÙØ¹Ø§Ù„ Ø§Ø³Øª
- [ ] WebSocket Ø±ÙˆÛŒ wss:// Ú©Ø§Ø± Ù…ÛŒâ€ŒÚ©Ù†Ù‡
- [ ] Monitoring Ùˆ logging Ø±Ø§Ù‡â€ŒØ§Ù†Ø¯Ø§Ø²ÛŒ Ø´Ø¯Ù‡

---

## ğŸ‰ Ù†ØªÛŒØ¬Ù‡

Ø§Ù„Ø§Ù† Ø¯Ø§Ø±ÛŒ:
- âœ… Ø³ÛŒØ³ØªÙ… Ú©Ø§Ù…Ù„ Ø¨Ø§ TypeScript
- âœ… API Client Ø¨Ø§ WebSocket
- âœ… Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ ÙˆØ§Ù‚Ø¹ÛŒ Ø§Ø² Hugging Face
- âœ… Training pipeline Ú©Ø§Ù…Ù„
- âœ… Dashboard Ø¨Ø§ Real-time monitoring
- âœ… Ù…Ø³ØªÙ†Ø¯Ø§Øª Ø¬Ø§Ù…Ø¹

**Ù‡Ù…Ù‡ Ú†ÛŒØ² Ø¢Ù…Ø§Ø¯Ù‡ Ø¨Ø±Ø§ÛŒ Ú©Ø§Ø± Ø¨Ø§ Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ ÙˆØ§Ù‚Ø¹ÛŒ!** ğŸš€

---

**Ù„ÛŒÙ†Ú©â€ŒÙ‡Ø§ÛŒ Ù…Ù‡Ù…**:
- ğŸ¤– Ù…Ø¯Ù„â€ŒÙ‡Ø§: https://huggingface.co/models?language=fa
- ğŸ“Š Ø¯ÛŒØªØ§Ø³Øªâ€ŒÙ‡Ø§: https://huggingface.co/datasets?language=fa
- ğŸ“š Ù…Ø³ØªÙ†Ø¯Ø§Øª: https://huggingface.co/docs/transformers
