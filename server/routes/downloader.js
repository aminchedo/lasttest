import express from 'express';
import axios from 'axios';
import fs from 'fs/promises';
import path from 'path';
import { v4 as uuidv4 } from 'uuid';
import { runAsync, getAsync, allAsync } from '../db.js';

const router = express.Router();

// Ù…Ù†Ø§Ø¨Ø¹ Ù…Ø®ØªÙ„Ù Ø¨Ø±Ø§ÛŒ Ø¯Ø§Ù†Ù„ÙˆØ¯
const DOWNLOAD_SOURCES = {
  datasets: {
    persian_news: {
      name: 'Persian News Dataset',
      url: 'https://raw.githubusercontent.com/persiannlp/persian-news-dataset/main/sample.txt',
      type: 'text',
      language: 'fa',
      description: 'Ù…Ø¬Ù…ÙˆØ¹Ù‡ Ø¯Ø§Ø¯Ù‡ Ø§Ø®Ø¨Ø§Ø± ÙØ§Ø±Ø³ÛŒ'
    },
    persian_wikipedia: {
      name: 'Persian Wikipedia Sample',
      url: 'https://raw.githubusercontent.com/persiannlp/persian-wikipedia/main/sample.txt',
      type: 'text',
      language: 'fa',
      description: 'Ù†Ù…ÙˆÙ†Ù‡ ÙˆÛŒÚ©ÛŒâ€ŒÙ¾Ø¯ÛŒØ§ ÙØ§Ø±Ø³ÛŒ'
    },
    english_tech: {
      name: 'English Tech Articles',
      url: 'https://raw.githubusercontent.com/tech-articles/english-tech/main/sample.txt',
      type: 'text',
      language: 'en',
      description: 'Ù…Ù‚Ø§Ù„Ø§Øª ÙÙ†Ø§ÙˆØ±ÛŒ Ø§Ù†Ú¯Ù„ÛŒØ³ÛŒ'
    }
  },
  models: {
    bert_persian: {
      name: 'HooshvareLab/bert-fa-base-uncased',
      url: 'huggingface',
      type: 'transformer',
      language: 'fa',
      description: 'Ù…Ø¯Ù„ BERT ÙØ§Ø±Ø³ÛŒ - Fill Mask'
    },
    gpt2_persian: {
      name: 'HooshvareLab/gpt2-fa',
      url: 'huggingface',
      type: 'generative',
      language: 'fa',
      description: 'Ù…Ø¯Ù„ GPT-2 ÙØ§Ø±Ø³ÛŒ - ØªÙˆÙ„ÛŒØ¯ Ù…ØªÙ†'
    },
    t5_persian: {
      name: 'persiannlp/mt5-base-parsinlu-translation_fa_en',
      url: 'huggingface',
      type: 'text-to-text',
      language: 'fa',
      description: 'Ù…Ø¯Ù„ ØªØ±Ø¬Ù…Ù‡ ÙØ§Ø±Ø³ÛŒ-Ø§Ù†Ú¯Ù„ÛŒØ³ÛŒ'
    },
    bert_base: {
      name: 'bert-base-uncased',
      url: 'huggingface',
      type: 'transformer',
      language: 'en',
      description: 'BERT Base Model'
    },
    gpt2_base: {
      name: 'gpt2',
      url: 'huggingface',
      type: 'generative',
      language: 'en',
      description: 'GPT-2 Base Model'
    }
  },
  tts: {
    persian_female: {
      name: 'Persian Female Voice',
      url: 'https://huggingface.co/m3hrdadfi/tts-fa-female/resolve/main/model.bin',
      type: 'voice',
      language: 'fa',
      description: 'ØµØ¯Ø§ÛŒ Ø²Ù† ÙØ§Ø±Ø³ÛŒ'
    },
    persian_male: {
      name: 'Persian Male Voice',
      url: 'https://huggingface.co/m3hrdadfi/tts-fa-male/resolve/main/model.bin',
      type: 'voice',
      language: 'fa',
      description: 'ØµØ¯Ø§ÛŒ Ù…Ø±Ø¯ ÙØ§Ø±Ø³ÛŒ'
    },
    english_female: {
      name: 'English Female Voice',
      url: 'https://huggingface.co/facebook/tts-en-female/resolve/main/model.bin',
      type: 'voice',
      language: 'en',
      description: 'English Female Voice'
    }
  }
};

// Ø¯Ø±ÛŒØ§ÙØª Ù„ÛŒØ³Øª Ù…Ù†Ø§Ø¨Ø¹ Ù‚Ø§Ø¨Ù„ Ø¯Ø§Ù†Ù„ÙˆØ¯
router.get('/sources', (req, res) => {
  try {
    res.json({
      success: true,
      sources: DOWNLOAD_SOURCES
    });
  } catch (error) {
    console.error('âŒ Ø®Ø·Ø§ Ø¯Ø± Ø¯Ø±ÛŒØ§ÙØª Ù…Ù†Ø§Ø¨Ø¹:', error);
    res.status(500).json({ error: 'Ø®Ø·Ø§ Ø¯Ø± Ø¯Ø±ÛŒØ§ÙØª Ù…Ù†Ø§Ø¨Ø¹ Ø¯Ø§Ù†Ù„ÙˆØ¯' });
  }
});

// Ø¯Ø§Ù†Ù„ÙˆØ¯ dataset
router.post('/dataset', async (req, res) => {
  try {
    const { source, customUrl, name, description } = req.body;
    
    let downloadInfo;
    if (source && DOWNLOAD_SOURCES.datasets[source]) {
      downloadInfo = DOWNLOAD_SOURCES.datasets[source];
    } else if (customUrl) {
      downloadInfo = {
        name: name || 'Custom Dataset',
        url: customUrl,
        type: 'text',
        language: 'fa',
        description: description || 'Ø¯ÛŒØªØ§Ø³Øª Ø³ÙØ§Ø±Ø´ÛŒ'
      };
    } else {
      return res.status(400).json({ error: 'Ù…Ù†Ø¨Ø¹ ÛŒØ§ URL Ø³ÙØ§Ø±Ø´ÛŒ Ø§Ù„Ø²Ø§Ù…ÛŒ Ø§Ø³Øª' });
    }

    console.log(`ğŸ“¥ Ø´Ø±ÙˆØ¹ Ø¯Ø§Ù†Ù„ÙˆØ¯ dataset: ${downloadInfo.name}`);
    
    // Ø§ÛŒØ¬Ø§Ø¯ ID Ù…Ù†Ø­ØµØ± Ø¨Ù‡ ÙØ±Ø¯
    const datasetId = `dataset-${Date.now()}-${uuidv4().slice(0, 8)}`;
    const fileName = `${datasetId}.txt`;
    const filePath = path.join(process.cwd(), 'data', 'datasets', fileName);
    
    // Ø§Ø·Ù…ÛŒÙ†Ø§Ù† Ø§Ø² ÙˆØ¬ÙˆØ¯ Ù¾ÙˆØ´Ù‡
    await fs.mkdir(path.dirname(filePath), { recursive: true });
    
    // Ø¯Ø§Ù†Ù„ÙˆØ¯ ÙØ§ÛŒÙ„
    const response = await axios.get(downloadInfo.url, {
      responseType: 'stream',
      timeout: 30000
    });
    
    // Ø°Ø®ÛŒØ±Ù‡ ÙØ§ÛŒÙ„
    const writer = require('fs').createWriteStream(filePath);
    response.data.pipe(writer);
    
    return new Promise((resolve, reject) => {
      writer.on('finish', async () => {
        try {
          // Ø¯Ø±ÛŒØ§ÙØª Ø§Ø·Ù„Ø§Ø¹Ø§Øª ÙØ§ÛŒÙ„
          const stats = await fs.stat(filePath);
          const fileSize = stats.size;
          
          // Ø°Ø®ÛŒØ±Ù‡ Ø¯Ø± Ø¯ÛŒØªØ§Ø¨ÛŒØ³
          await runAsync(
            `INSERT INTO assets (id, kind, model_id, file_name, file_size, bytes_total, local_path, status, created_at, updated_at)
             VALUES (?, 'dataset', ?, ?, ?, ?, ?, 'ready', CURRENT_TIMESTAMP, CURRENT_TIMESTAMP)`,
            [datasetId, downloadInfo.name, fileName, fileSize, fileSize, filePath]
          );
          
          console.log(`âœ… Dataset Ø¯Ø§Ù†Ù„ÙˆØ¯ Ø´Ø¯: ${downloadInfo.name}`);
          resolve(res.json({
            success: true,
            message: 'Dataset Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ø¯Ø§Ù†Ù„ÙˆØ¯ Ø´Ø¯',
            dataset: {
              id: datasetId,
              name: downloadInfo.name,
              size: formatFileSize(fileSize),
              type: downloadInfo.type,
              language: downloadInfo.language,
              status: 'ready',
              localPath: filePath
            }
          }));
        } catch (error) {
          console.error('âŒ Ø®Ø·Ø§ Ø¯Ø± Ø°Ø®ÛŒØ±Ù‡ dataset:', error);
          reject(res.status(500).json({ error: 'Ø®Ø·Ø§ Ø¯Ø± Ø°Ø®ÛŒØ±Ù‡ dataset' }));
        }
      });
      
      writer.on('error', (error) => {
        console.error('âŒ Ø®Ø·Ø§ Ø¯Ø± Ø¯Ø§Ù†Ù„ÙˆØ¯ dataset:', error);
        reject(res.status(500).json({ error: 'Ø®Ø·Ø§ Ø¯Ø± Ø¯Ø§Ù†Ù„ÙˆØ¯ dataset' }));
      });
    });
    
  } catch (error) {
    console.error('âŒ Ø®Ø·Ø§ Ø¯Ø± Ø¯Ø§Ù†Ù„ÙˆØ¯ dataset:', error);
    res.status(500).json({ error: 'Ø®Ø·Ø§ Ø¯Ø± Ø¯Ø§Ù†Ù„ÙˆØ¯ dataset' });
  }
});

// Ø¯Ø§Ù†Ù„ÙˆØ¯ Ù…Ø¯Ù„
router.post('/model', async (req, res) => {
  try {
    const { source, customUrl, name, description, modelType } = req.body;
    
    let downloadInfo;
    if (source && DOWNLOAD_SOURCES.models[source]) {
      downloadInfo = DOWNLOAD_SOURCES.models[source];
    } else if (customUrl) {
      downloadInfo = {
        name: name || 'Custom Model',
        url: customUrl,
        type: modelType || 'transformer',
        language: 'fa',
        description: description || 'Ù…Ø¯Ù„ Ø³ÙØ§Ø±Ø´ÛŒ'
      };
    } else {
      return res.status(400).json({ error: 'Ù…Ù†Ø¨Ø¹ ÛŒØ§ URL Ø³ÙØ§Ø±Ø´ÛŒ Ø§Ù„Ø²Ø§Ù…ÛŒ Ø§Ø³Øª' });
    }

    console.log(`ğŸ“¥ Ø´Ø±ÙˆØ¹ Ø¯Ø§Ù†Ù„ÙˆØ¯ Ù…Ø¯Ù„: ${downloadInfo.name}`);
    
    // Ø§ÛŒØ¬Ø§Ø¯ ID Ù…Ù†Ø­ØµØ± Ø¨Ù‡ ÙØ±Ø¯
    const modelId = `model-${Date.now()}-${uuidv4().slice(0, 8)}`;
    const fileName = `${modelId}.bin`;
    const filePath = path.join(process.cwd(), 'data', 'models', fileName);
    
    // Ø§Ø·Ù…ÛŒÙ†Ø§Ù† Ø§Ø² ÙˆØ¬ÙˆØ¯ Ù¾ÙˆØ´Ù‡
    await fs.mkdir(path.dirname(filePath), { recursive: true });
    
    // Ø¯Ø§Ù†Ù„ÙˆØ¯ ÙØ§ÛŒÙ„
    const response = await axios.get(downloadInfo.url, {
      responseType: 'stream',
      timeout: 60000
    });
    
    // Ø°Ø®ÛŒØ±Ù‡ ÙØ§ÛŒÙ„
    const writer = require('fs').createWriteStream(filePath);
    response.data.pipe(writer);
    
    return new Promise((resolve, reject) => {
      writer.on('finish', async () => {
        try {
          // Ø¯Ø±ÛŒØ§ÙØª Ø§Ø·Ù„Ø§Ø¹Ø§Øª ÙØ§ÛŒÙ„
          const stats = await fs.stat(filePath);
          const fileSize = stats.size;
          
          // Ø°Ø®ÛŒØ±Ù‡ Ø¯Ø± Ø¯ÛŒØªØ§Ø¨ÛŒØ³
          await runAsync(
            `INSERT INTO models (id, name, type, language, file_path, file_size, status, created_at, updated_at)
             VALUES (?, ?, ?, ?, ?, ?, 'ready', CURRENT_TIMESTAMP, CURRENT_TIMESTAMP)`,
            [modelId, downloadInfo.name, downloadInfo.type, downloadInfo.language, filePath, fileSize]
          );
          
          console.log(`âœ… Ù…Ø¯Ù„ Ø¯Ø§Ù†Ù„ÙˆØ¯ Ø´Ø¯: ${downloadInfo.name}`);
          resolve(res.json({
            success: true,
            message: 'Ù…Ø¯Ù„ Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ø¯Ø§Ù†Ù„ÙˆØ¯ Ø´Ø¯',
            model: {
              id: modelId,
              name: downloadInfo.name,
              type: downloadInfo.type,
              language: downloadInfo.language,
              size: formatFileSize(fileSize),
              status: 'ready',
              filePath: filePath
            }
          }));
        } catch (error) {
          console.error('âŒ Ø®Ø·Ø§ Ø¯Ø± Ø°Ø®ÛŒØ±Ù‡ Ù…Ø¯Ù„:', error);
          reject(res.status(500).json({ error: 'Ø®Ø·Ø§ Ø¯Ø± Ø°Ø®ÛŒØ±Ù‡ Ù…Ø¯Ù„' }));
        }
      });
      
      writer.on('error', (error) => {
        console.error('âŒ Ø®Ø·Ø§ Ø¯Ø± Ø¯Ø§Ù†Ù„ÙˆØ¯ Ù…Ø¯Ù„:', error);
        reject(res.status(500).json({ error: 'Ø®Ø·Ø§ Ø¯Ø± Ø¯Ø§Ù†Ù„ÙˆØ¯ Ù…Ø¯Ù„' }));
      });
    });
    
  } catch (error) {
    console.error('âŒ Ø®Ø·Ø§ Ø¯Ø± Ø¯Ø§Ù†Ù„ÙˆØ¯ Ù…Ø¯Ù„:', error);
    res.status(500).json({ error: 'Ø®Ø·Ø§ Ø¯Ø± Ø¯Ø§Ù†Ù„ÙˆØ¯ Ù…Ø¯Ù„' });
  }
});

// Ø¯Ø§Ù†Ù„ÙˆØ¯ TTS
router.post('/tts', async (req, res) => {
  try {
    const { source, customUrl, name, description, voiceType } = req.body;
    
    let downloadInfo;
    if (source && DOWNLOAD_SOURCES.tts[source]) {
      downloadInfo = DOWNLOAD_SOURCES.tts[source];
    } else if (customUrl) {
      downloadInfo = {
        name: name || 'Custom TTS',
        url: customUrl,
        type: 'voice',
        language: 'fa',
        description: description || 'TTS Ø³ÙØ§Ø±Ø´ÛŒ'
      };
    } else {
      return res.status(400).json({ error: 'Ù…Ù†Ø¨Ø¹ ÛŒØ§ URL Ø³ÙØ§Ø±Ø´ÛŒ Ø§Ù„Ø²Ø§Ù…ÛŒ Ø§Ø³Øª' });
    }

    console.log(`ğŸ“¥ Ø´Ø±ÙˆØ¹ Ø¯Ø§Ù†Ù„ÙˆØ¯ TTS: ${downloadInfo.name}`);
    
    // Ø§ÛŒØ¬Ø§Ø¯ ID Ù…Ù†Ø­ØµØ± Ø¨Ù‡ ÙØ±Ø¯
    const ttsId = `tts-${Date.now()}-${uuidv4().slice(0, 8)}`;
    const fileName = `${ttsId}.bin`;
    const filePath = path.join(process.cwd(), 'data', 'tts', fileName);
    
    // Ø§Ø·Ù…ÛŒÙ†Ø§Ù† Ø§Ø² ÙˆØ¬ÙˆØ¯ Ù¾ÙˆØ´Ù‡
    await fs.mkdir(path.dirname(filePath), { recursive: true });
    
    // Ø¯Ø§Ù†Ù„ÙˆØ¯ ÙØ§ÛŒÙ„
    const response = await axios.get(downloadInfo.url, {
      responseType: 'stream',
      timeout: 60000
    });
    
    // Ø°Ø®ÛŒØ±Ù‡ ÙØ§ÛŒÙ„
    const writer = require('fs').createWriteStream(filePath);
    response.data.pipe(writer);
    
    return new Promise((resolve, reject) => {
      writer.on('finish', async () => {
        try {
          // Ø¯Ø±ÛŒØ§ÙØª Ø§Ø·Ù„Ø§Ø¹Ø§Øª ÙØ§ÛŒÙ„
          const stats = await fs.stat(filePath);
          const fileSize = stats.size;
          
          // Ø°Ø®ÛŒØ±Ù‡ Ø¯Ø± Ø¯ÛŒØªØ§Ø¨ÛŒØ³
          await runAsync(
            `INSERT INTO tts_models (id, name, type, language, file_path, file_size, status, created_at, updated_at)
             VALUES (?, ?, ?, ?, ?, ?, 'ready', CURRENT_TIMESTAMP, CURRENT_TIMESTAMP)`,
            [ttsId, downloadInfo.name, downloadInfo.type, downloadInfo.language, filePath, fileSize]
          );
          
          console.log(`âœ… TTS Ø¯Ø§Ù†Ù„ÙˆØ¯ Ø´Ø¯: ${downloadInfo.name}`);
          resolve(res.json({
            success: true,
            message: 'TTS Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ø¯Ø§Ù†Ù„ÙˆØ¯ Ø´Ø¯',
            tts: {
              id: ttsId,
              name: downloadInfo.name,
              type: downloadInfo.type,
              language: downloadInfo.language,
              size: formatFileSize(fileSize),
              status: 'ready',
              filePath: filePath
            }
          }));
        } catch (error) {
          console.error('âŒ Ø®Ø·Ø§ Ø¯Ø± Ø°Ø®ÛŒØ±Ù‡ TTS:', error);
          reject(res.status(500).json({ error: 'Ø®Ø·Ø§ Ø¯Ø± Ø°Ø®ÛŒØ±Ù‡ TTS' }));
        }
      });
      
      writer.on('error', (error) => {
        console.error('âŒ Ø®Ø·Ø§ Ø¯Ø± Ø¯Ø§Ù†Ù„ÙˆØ¯ TTS:', error);
        reject(res.status(500).json({ error: 'Ø®Ø·Ø§ Ø¯Ø± Ø¯Ø§Ù†Ù„ÙˆØ¯ TTS' }));
      });
    });
    
  } catch (error) {
    console.error('âŒ Ø®Ø·Ø§ Ø¯Ø± Ø¯Ø§Ù†Ù„ÙˆØ¯ TTS:', error);
    res.status(500).json({ error: 'Ø®Ø·Ø§ Ø¯Ø± Ø¯Ø§Ù†Ù„ÙˆØ¯ TTS' });
  }
});

// Ø¯Ø±ÛŒØ§ÙØª ÙˆØ¶Ø¹ÛŒØª Ø¯Ø§Ù†Ù„ÙˆØ¯Ù‡Ø§
router.get('/status', async (req, res) => {
  try {
    const [datasets, models, ttsModels] = await Promise.all([
      allAsync("SELECT * FROM assets WHERE kind = 'dataset' ORDER BY created_at DESC"),
      allAsync("SELECT * FROM models ORDER BY created_at DESC"),
      allAsync("SELECT * FROM tts_models ORDER BY created_at DESC")
    ]);

    res.json({
      success: true,
      status: {
        datasets: datasets.length,
        models: models.length,
        tts: ttsModels.length,
        total: datasets.length + models.length + ttsModels.length
      },
      items: {
        datasets: datasets.map(ds => ({
          id: ds.id,
          name: ds.model_id || ds.file_name,
          size: formatFileSize(ds.bytes_total),
          status: ds.status,
          createdAt: ds.created_at
        })),
        models: models.map(m => ({
          id: m.id,
          name: m.name,
          type: m.type,
          size: formatFileSize(m.file_size),
          status: m.status,
          createdAt: m.created_at
        })),
        tts: ttsModels.map(t => ({
          id: t.id,
          name: t.name,
          type: t.type,
          size: formatFileSize(t.file_size),
          status: t.status,
          createdAt: t.created_at
        }))
      }
    });
  } catch (error) {
    console.error('âŒ Ø®Ø·Ø§ Ø¯Ø± Ø¯Ø±ÛŒØ§ÙØª ÙˆØ¶Ø¹ÛŒØª:', error);
    res.status(500).json({ error: 'Ø®Ø·Ø§ Ø¯Ø± Ø¯Ø±ÛŒØ§ÙØª ÙˆØ¶Ø¹ÛŒØª Ø¯Ø§Ù†Ù„ÙˆØ¯Ù‡Ø§' });
  }
});

// ØªØ§Ø¨Ø¹ Ú©Ù…Ú©ÛŒ Ø¨Ø±Ø§ÛŒ ÙØ±Ù…Øª Ú©Ø±Ø¯Ù† Ø§Ù†Ø¯Ø§Ø²Ù‡ ÙØ§ÛŒÙ„
function formatFileSize(bytes) {
  if (bytes === 0) return '0 Bytes';
  const k = 1024;
  const sizes = ['Bytes', 'KB', 'MB', 'GB', 'TB'];
  const i = Math.floor(Math.log(bytes) / Math.log(k));
  return parseFloat((bytes / Math.pow(k, i)).toFixed(2)) + ' ' + sizes[i];
}

export default router;
