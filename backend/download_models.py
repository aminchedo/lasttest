#!/usr/bin/env python3
"""
Ø§Ø³Ú©Ø±ÛŒÙ¾Øª Ø¯Ø§Ù†Ù„ÙˆØ¯ Ø®ÙˆØ¯Ú©Ø§Ø± Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Hugging Face
Usage: python download_models.py [--models MODEL1,MODEL2,...]
"""

import os
import sys
import argparse
from pathlib import Path
from typing import Dict, List
from transformers import (
    AutoModel,
    AutoTokenizer,
    GPT2LMHeadModel,
    AutoModelForSequenceClassification,
    AutoModelForTokenClassification,
    MT5ForConditionalGeneration,
    MT5Tokenizer
)

# ØªØ¹Ø±ÛŒÙ Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Ù…ÙˆØ¬ÙˆØ¯
AVAILABLE_MODELS = {
    # Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Ù¾Ø§ÛŒÙ‡
    "parsbert": {
        "id": "HooshvareLab/bert-fa-base-uncased",
        "type": "base",
        "size": "440MB",
        "params": "118M"
    },
    "mt5-base": {
        "id": "google/mt5-base",
        "type": "mt5",
        "size": "2.3GB",
        "params": "580M"
    },
    "xlm-roberta-base": {
        "id": "xlm-roberta-base",
        "type": "base",
        "size": "1.1GB",
        "params": "270M"
    },
    "gpt2-persian": {
        "id": "flax-community/gpt2-persian",
        "type": "gpt2",
        "size": "500MB",
        "params": "124M"
    },
    
    # Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Fine-tuned
    "parsbert-sentiment": {
        "id": "HooshvareLab/bert-fa-base-uncased-sentiment-digikala",
        "type": "sequence-classification",
        "size": "440MB",
        "params": "118M"
    },
    "parsbert-ner": {
        "id": "HooshvareLab/bert-fa-base-uncased-ner-peyma",
        "type": "token-classification",
        "size": "440MB",
        "params": "118M"
    }
}


class ModelDownloader:
    """Ø¯Ø§Ù†Ù„ÙˆØ¯Ø± Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Hugging Face"""
    
    def __init__(self, base_path: str = "./models"):
        self.base_path = Path(base_path)
        self.base_path.mkdir(parents=True, exist_ok=True)
        
    def download_model(self, name: str, model_info: Dict) -> bool:
        """Ø¯Ø§Ù†Ù„ÙˆØ¯ ÛŒÚ© Ù…Ø¯Ù„ Ø§Ø² Hugging Face"""
        model_id = model_info["id"]
        model_type = model_info["type"]
        model_path = self.base_path / name
        
        print(f"\n{'='*60}")
        print(f"ğŸ“¦ Ø¯Ø§Ù†Ù„ÙˆØ¯ {name}")
        print(f"   ID: {model_id}")
        print(f"   Size: {model_info['size']}")
        print(f"{'='*60}")
        
        try:
            print(f"â³ Ø¯Ø± Ø­Ø§Ù„ Ø¯Ø§Ù†Ù„ÙˆØ¯ Ù…Ø¯Ù„...")
            
            if model_type == "gpt2":
                model = GPT2LMHeadModel.from_pretrained(model_id)
            elif model_type == "mt5":
                model = MT5ForConditionalGeneration.from_pretrained(model_id)
            elif model_type == "sequence-classification":
                model = AutoModelForSequenceClassification.from_pretrained(model_id)
            elif model_type == "token-classification":
                model = AutoModelForTokenClassification.from_pretrained(model_id)
            else:
                model = AutoModel.from_pretrained(model_id)
            
            print(f"â³ Ø¯Ø± Ø­Ø§Ù„ Ø¯Ø§Ù†Ù„ÙˆØ¯ tokenizer...")
            if model_type == "mt5":
                tokenizer = MT5Tokenizer.from_pretrained(model_id)
            else:
                tokenizer = AutoTokenizer.from_pretrained(model_id)
            
            print(f"ğŸ’¾ Ø¯Ø± Ø­Ø§Ù„ Ø°Ø®ÛŒØ±Ù‡...")
            model.save_pretrained(model_path)
            tokenizer.save_pretrained(model_path)
            
            print(f"âœ… {name} Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ø¯Ø§Ù†Ù„ÙˆØ¯ Ø´Ø¯!")
            return True
                
        except Exception as e:
            print(f"âŒ Ø®Ø·Ø§ Ø¯Ø± Ø¯Ø§Ù†Ù„ÙˆØ¯ {name}: {str(e)}")
            return False
    
    def download_all(self, model_names: List[str] = None) -> Dict[str, bool]:
        """Ø¯Ø§Ù†Ù„ÙˆØ¯ Ú†Ù†Ø¯ Ù…Ø¯Ù„"""
        if model_names is None:
            model_names = ["parsbert", "gpt2-persian"]  # ÙÙ‚Ø· Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Ø§ØµÙ„ÛŒ
        
        results = {}
        for name in model_names:
            if name not in AVAILABLE_MODELS:
                print(f"âš ï¸  Ù…Ø¯Ù„ '{name}' ÛŒØ§ÙØª Ù†Ø´Ø¯.")
                results[name] = False
                continue
            
            results[name] = self.download_model(name, AVAILABLE_MODELS[name])
        
        return results


def main():
    """ØªØ§Ø¨Ø¹ Ø§ØµÙ„ÛŒ"""
    parser = argparse.ArgumentParser(description="Ø¯Ø§Ù†Ù„ÙˆØ¯ Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Hugging Face")
    parser.add_argument("--models", type=str, help="Ù„ÛŒØ³Øª Ù…Ø¯Ù„â€ŒÙ‡Ø§")
    parser.add_argument("--list", action="store_true", help="Ù†Ù…Ø§ÛŒØ´ Ù„ÛŒØ³Øª")
    parser.add_argument("--path", type=str, default="./models", help="Ù…Ø³ÛŒØ± Ø°Ø®ÛŒØ±Ù‡")
    
    args = parser.parse_args()
    
    if args.list:
        print("\nğŸ“¦ Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Ù…ÙˆØ¬ÙˆØ¯:\n")
        for name, info in AVAILABLE_MODELS.items():
            print(f"  â€¢ {name:20} - {info['size']}")
            print(f"    {info['id']}\n")
        return
    
    downloader = ModelDownloader(base_path=args.path)
    model_names = [m.strip() for m in args.models.split(",")] if args.models else None
    results = downloader.download_all(model_names)
    
    print(f"\n{'='*60}")
    print(f"âœ… Ù…ÙˆÙÙ‚: {sum(1 for v in results.values() if v)}")
    print(f"âŒ Ù†Ø§Ù…ÙˆÙÙ‚: {sum(1 for v in results.values() if not v)}")
    print(f"{'='*60}\n")


if __name__ == "__main__":
    main()
